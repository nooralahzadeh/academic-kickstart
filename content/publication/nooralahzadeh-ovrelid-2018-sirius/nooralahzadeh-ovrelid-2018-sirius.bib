@inproceedings{nooralahzadeh-ovrelid-2018-sirius,
 abstract = {This article presents the SIRIUS-LTG system for the Fact Extraction and VERification (FEVER) SharedTask. It consists of three components: 1)Wikipedia Page Retrieval: First we extract the entities in the claim, then we find potential Wikipedia URI candidates for each of the entities using a SPARQL query over DBpedia 2)Sentence selection: We investigate various techniques i.e. Smooth Inverse Frequency(SIF), Word Mover′s Distance (WMD), Soft-Cosine Similarity, Cosine similarity with uni-gram Term Frequency Inverse Document Frequency (TF-IDF) to rank sentences by their similarity to the claim. 3)Textual Entailment: We compare three models for the task of claim classification. We apply a Decomposable Attention (DA) model (Parikh et al., 2016), a Decomposed Graph Entailment (DGE) model (Khot et al., 2018) and a Gradient-Boosted Decision Trees (TalosTree) model (Sean et al.,2017) for this task. The experiments show that the pipeline with simple Cosine Similarity using TFIDF in sentence selection along with DA model as labelling model achieves the best results on the development set (F1evidence: 32.17, label accuracy: 59.61 andFEVER score: 0.3778). Furthermore, it obtains 30.19, 48.87 and 36.55 in terms of F1 evidence, label accuracy and FEVER score, respectively, on the test set. Our system ranks 15th among 23 participants in the shared task prior to any human-evaluation of the evidence.},
 address = {Brussels, Belgium},
 author = {Nooralahzadeh, Farhad  and
Øvrelid, Lilja},
 booktitle = {Proceedings of the First Workshop on Fact Extraction and VERification (FEVER)},
 month = {November},
 pages = {119--123},
 publisher = {Association for Computational Linguistics},
 title = {SIRIUS-LTG: An Entity Linking Approach to Fact Extraction and Verification},
 url = {https://www.aclweb.org/anthology/W18-5519},
 year = {2018}
}

